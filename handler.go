package rerpc

import (
	"context"
	"errors"
	"fmt"
	"io"
	"net/http"
	"strings"
)

var (
	// Always advertise that reRPC accepts gzip compression.
	acceptEncodingValue      = strings.Join([]string{CompressionGzip, CompressionIdentity}, ",")
	acceptEncodingValueSlice = []string{acceptEncodingValue}
	acceptPostValueDefault   = strings.Join(
		[]string{TypeDefaultGRPC, TypeProtoGRPC, TypeProtoTwirp, TypeJSON},
		",",
	)
	acceptPostValueWithoutTwirp = strings.Join(
		[]string{TypeDefaultGRPC, TypeProtoGRPC},
		",",
	)
	grpcStatusTrailers = []string{"Grpc-Status", "Grpc-Message", "Grpc-Status-Details-Bin"}
)

type handlerCfg struct {
	DisableGzipResponse bool
	DisableTwirp        bool
	MaxRequestBytes     int64
	Registrar           *Registrar
	Interceptor         Interceptor
	DisableRegistration bool
	Package             string
	Service             string
	Method              string
}

// A HandlerOption configures a Handler.
//
// In addition to any options grouped in the documentation below, remember that
// Registrars and Options are also valid HandlerOptions.
type HandlerOption interface {
	applyToHandler(*handlerCfg)
}

type serveTwirpOption struct {
	Disable bool
}

func (o *serveTwirpOption) applyToHandler(cfg *handlerCfg) {
	cfg.DisableTwirp = o.Disable
}

// ServeTwirp enables or disables support for Twirp's JSON and protobuf
// formats. Disable Twirp if you only want your handlers to speak the gRPC
// protocol.
//
// By default, handlers support Twirp.
func ServeTwirp(enable bool) HandlerOption {
	return &serveTwirpOption{!enable}
}

// A Handler is the server-side implementation of a single RPC defined by a
// protocol buffer service. It's the interface between the reRPC library and
// the code generated by the reRPC protoc plugin; most users won't ever need to
// deal with it directly.
//
// To see an example of how Handler is used in the generated code, see the
// internal/ping/v1test package.
type Handler struct {
	stype          StreamType
	config         handlerCfg
	implementation func(context.Context, Stream)
}

// NewUnaryHandler constructs a Handler. The supplied package, service, and
// method names must be protobuf identifiers. For example, a handler for the
// URL "/acme.foo.v1.FooService/Bar" would have package "acme.foo.v1", service
// "FooService", and method "Bar".
//
// Remember that NewUnaryHandler is usually called from generated code - most
// users won't need to deal with protobuf identifiers directly.
func NewUnaryHandler[Req, Res any](
	pkg, service, method string,
	implementation func(context.Context, *Request[Req]) (*Response[Res], error),
	opts ...HandlerOption,
) *Handler {
	cfg := handlerCfg{
		Package: pkg,
		Service: service,
		Method:  method,
	}
	for _, opt := range opts {
		opt.applyToHandler(&cfg)
	}
	if reg := cfg.Registrar; reg != nil && !cfg.DisableRegistration {
		reg.register(cfg.Package, cfg.Service)
	}

	untyped := Func(func(ctx context.Context, req AnyRequest) (AnyResponse, error) {
		typed, ok := req.(*Request[Req])
		if !ok {
			return nil, Errorf(CodeInternal, "unexpected handler request type %T", req)
		}
		return implementation(ctx, typed)
	})
	if ic := cfg.Interceptor; ic != nil {
		untyped = ic.Wrap(untyped)
	}
	streamer := func(ctx context.Context, stream Stream) {
		defer stream.CloseReceive()
		if err := ctx.Err(); err != nil {
			// TODO: Factor out repeated context error coding.
			if errors.Is(err, context.Canceled) {
				_ = stream.CloseSend(Wrap(CodeCanceled, err))
				return
			}
			if errors.Is(err, context.DeadlineExceeded) {
				_ = stream.CloseSend(Wrap(CodeDeadlineExceeded, err))
				return
			}
			_ = stream.CloseSend(err) // unreachable per context docs
		}
		req, err := NewReceivedRequest[Req](stream)
		if err != nil {
			_ = stream.CloseSend(err)
			return
		}
		res, err := untyped(ctx, req)
		if err != nil {
			if _, ok := AsError(err); !ok {
				if errors.Is(err, context.Canceled) {
					err = Wrap(CodeCanceled, err)
				}
				if errors.Is(err, context.DeadlineExceeded) {
					err = Wrap(CodeDeadlineExceeded, err)
				}
			}
			_ = stream.CloseSend(err)
			return
		}
		for k, v := range res.Header().raw {
			stream.Header().raw[k] = v
		}
		_ = stream.CloseSend(stream.Send(res.Any()))
	}
	return &Handler{
		stype:          StreamTypeUnary,
		config:         cfg,
		implementation: streamer,
	}
}

// NewStreamingHandler constructs a Handler. The supplied package, service, and
// method names must be protobuf identifiers. For example, a handler for the
// URL "/acme.foo.v1.FooService/Bar" would have package "acme.foo.v1", service
// "FooService", and method "Bar".
//
// Remember that NewStreamingHandler is usually called from generated code -
// most users won't need to deal with protobuf identifiers directly.
func NewStreamingHandler(
	stype StreamType,
	pkg, service, method string,
	implementation func(context.Context, Stream),
	opts ...HandlerOption,
) *Handler {
	cfg := handlerCfg{
		Package: pkg,
		Service: service,
		Method:  method,
	}
	for _, opt := range opts {
		opt.applyToHandler(&cfg)
	}
	if reg := cfg.Registrar; reg != nil && !cfg.DisableRegistration {
		reg.register(cfg.Package, cfg.Service)
	}
	return &Handler{
		stype:          stype,
		config:         cfg,
		implementation: implementation,
	}
}

// ServeHTTP implements http.Handler.
func (h *Handler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
	// We don't need to defer functions  to close the request body or read to
	// EOF: the stream we construct later on already does that, and we only
	// return early when dealing with misbehaving clients. In those cases, it's
	// okay if we can't re-use the connection.

	isBidi := (h.stype & StreamTypeBidirectional) == StreamTypeBidirectional
	if isBidi && r.ProtoMajor < 2 {
		w.WriteHeader(http.StatusHTTPVersionNotSupported)
		io.WriteString(w, "bidirectional streaming requires HTTP/2")
		return
	}
	if r.Method != http.MethodPost {
		// grpc-go returns a 500 here, but interoperability with non-gRPC HTTP
		// clients is better if we return a 405.
		w.Header().Set("Allow", http.MethodPost)
		w.WriteHeader(http.StatusMethodNotAllowed)
		return
	}
	ctype := r.Header.Get("Content-Type")
	if (ctype == TypeJSON || ctype == TypeProtoTwirp) && (h.config.DisableTwirp || h.stype != StreamTypeUnary) {
		w.Header().Set("Accept-Post", acceptPostValueWithoutTwirp)
		w.WriteHeader(http.StatusUnsupportedMediaType)
		return
	}
	if ctype != TypeDefaultGRPC && ctype != TypeProtoGRPC && ctype != TypeProtoTwirp && ctype != TypeJSON {
		// grpc-go returns 500, but the spec recommends 415.
		// https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md#requests
		w.Header().Set("Accept-Post", acceptPostValueDefault)
		w.WriteHeader(http.StatusUnsupportedMediaType)
		return
	}

	procedure := fmt.Sprintf("%s.%s/%s", h.config.Package, h.config.Service, h.config.Method)
	spec := Specification{
		Type:      h.stype,
		Procedure: procedure,
		IsServer:  true,
	}

	// We need to parse metadata before entering the interceptor stack, but we'd
	// like to report errors to the client in a format they understand (if
	// possible). We'll collect any such errors here and use them to
	// short-circuit early later on.
	//
	// NB, future refactorings will need to take care to avoid typed nils here.
	var failed *Error

	timeout, err := parseTimeout(r.Header.Get("Grpc-Timeout"))
	if err != nil && err != errNoTimeout {
		// Errors here indicate that the client sent an invalid timeout header, so
		// the error text is safe to send back.
		failed = wrap(CodeInvalidArgument, err)
	} else if err == nil {
		ctx, cancel := context.WithTimeout(r.Context(), timeout)
		defer cancel()
		r = r.WithContext(ctx)
	} // else err == errNoTimeout, nothing to do

	requestCompression := CompressionIdentity
	responseCompression := CompressionIdentity
	if ctype == TypeJSON || ctype == TypeProtoTwirp {
		if r.Header.Get("Content-Encoding") == "gzip" {
			requestCompression = CompressionGzip
		}
		// TODO: Actually parse Accept-Encoding instead of this hackery.
		if !h.config.DisableGzipResponse && strings.Contains(r.Header.Get("Accept-Encoding"), "gzip") {
			responseCompression = CompressionGzip
		}
	} else {
		if me := r.Header.Get("Grpc-Encoding"); me != "" {
			switch me {
			case CompressionIdentity:
				requestCompression = CompressionIdentity
			case CompressionGzip:
				requestCompression = CompressionGzip
			default:
				// Per https://github.com/grpc/grpc/blob/master/doc/compression.md, we
				// should return CodeUnimplemented and specify acceptable compression(s)
				// (in addition to setting the Grpc-Accept-Encoding header).
				if failed == nil {
					failed = errorf(
						CodeUnimplemented,
						"unknown compression %q: accepted grpc-encoding values are %v",
						me, acceptEncodingValue,
					)
				}
			}
		}
		// Follow https://github.com/grpc/grpc/blob/master/doc/compression.md.
		// (The grpc-go implementation doesn't read the "grpc-accept-encoding" header
		// and doesn't support compression method asymmetry.)
		responseCompression = requestCompression
		if h.config.DisableGzipResponse {
			responseCompression = CompressionIdentity
		} else if mae := r.Header.Get("Grpc-Accept-Encoding"); mae != "" {
			for _, enc := range strings.FieldsFunc(mae, splitOnCommasAndSpaces) {
				switch enc {
				case CompressionGzip:
					responseCompression = CompressionGzip
					// prefer gzip, so no continue
				case CompressionIdentity:
					responseCompression = CompressionIdentity
					continue
				default:
					continue
				}
				break
			}
		}
	}

	// We should write any remaining headers here, since: (a) the implementation
	// may write to the body, thereby sending the headers, and (b) interceptors
	// should be able to see this data.
	//
	// Since we know that these header keys are already in canonical form, we can
	// skip the normalization in Header.Set. To avoid allocating re-allocating
	// the same slices over and over, we use pre-allocated globals for the header
	// values.
	w.Header()["Content-Type"] = typeToSlice(ctype)
	if ctype != TypeJSON && ctype != TypeProtoTwirp {
		w.Header()["Grpc-Accept-Encoding"] = acceptEncodingValueSlice
		w.Header()["Grpc-Encoding"] = compressionToSlice(responseCompression)
		// Every gRPC response will have these trailers.
		w.Header()["Trailer"] = grpcStatusTrailers
	}

	// Unlike gRPC, Twirp manages compression using the standard HTTP mechanisms.
	// Since they apply to the whole stream, it's easiest to handle it here.
	var requestBody io.Reader = r.Body
	if ctype == TypeJSON || ctype == TypeProtoTwirp {
		if requestCompression == CompressionGzip {
			gr, err := getGzipReader(requestBody)
			if err != nil && failed == nil {
				failed = errorf(CodeInvalidArgument, "can't read gzipped body: %w", err)
			} else if err == nil {
				defer putGzipReader(gr)
				defer gr.Close()
				requestBody = gr
			}
		}
		// Checking Content-Encoding ensures that some other user-supplied
		// middleware isn't already compressing the response.
		if responseCompression == CompressionGzip && w.Header().Get("Content-Encoding") == "" {
			w.Header().Set("Content-Encoding", "gzip")
			gw := getGzipWriter(w)
			defer putGzipWriter(gw)
			w = &gzipResponseWriter{ResponseWriter: w, gw: gw}
		}
	}

	sf := StreamFunc(func(ctx context.Context) (context.Context, Stream) {
		return ctx, newServerStream(
			spec,
			w,
			&readCloser{Reader: requestBody, Closer: r.Body},
			Header{raw: r.Header},
			ctype,
			h.config.MaxRequestBytes,
			responseCompression == CompressionGzip,
		)
	})
	if ic := h.config.Interceptor; ic != nil && h.stype != StreamTypeUnary {
		sf = ic.WrapStream(sf)
	}
	ctx, stream := sf(r.Context())
	if failed != nil {
		_ = stream.CloseReceive()
		_ = stream.CloseSend(failed)
		return
	}
	h.implementation(ctx, stream)
}

// Path returns the URL pattern to use when registering this handler. It's used
// by the generated code.
func (h *Handler) Path() string {
	if h.config.Package == "" && h.config.Service == "" && h.config.Method == "" {
		// e.g., bad route handler
		return "/"
	}
	return fmt.Sprintf("/%s.%s/%s", h.config.Package, h.config.Service, h.config.Method)
}

func splitOnCommasAndSpaces(c rune) bool {
	return c == ',' || c == ' '
}

type readCloser struct {
	io.Reader
	io.Closer
}
